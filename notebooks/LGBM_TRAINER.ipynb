{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a23b57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix,roc_curve,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "368fadfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import open_clip\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix,roc_curve\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "import albumentations as A\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "albumentations_aug = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(p=0.3),\n",
    "        A.GaussianBlur(blur_limit=5, p=0.5),\n",
    "        A.MedianBlur(blur_limit=5, p=0.5),\n",
    "    ], p=0.6),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.Downscale(scale_min=0.7, scale_max=0.95, p=0.3),\n",
    "    A.RandomResizedCrop(size=(672, 672), scale=(0.8, 1.0), ratio=(0.75, 1.33), p=0.4),\n",
    "    A.GaussNoise(var_limit=(5.0, 20.0), p=0.3),\n",
    "    A.ImageCompression(quality_lower=30, quality_upper=80, compression_type='jpeg', p=0.2),\n",
    "])\n",
    "\n",
    "# === 1. Load CLIP Model ===\n",
    "def load_clip(device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')\n",
    "    model.to(device).eval()\n",
    "    tokenizer = open_clip.get_tokenizer('ViT-B-32')\n",
    "    return model, preprocess, tokenizer, device\n",
    "\n",
    "# === 2. Pupil Cropping ===\n",
    "def crop_to_pupil(image_path, output_size=(512, 512)):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray_blur = cv2.medianBlur(gray, 5)\n",
    "\n",
    "    circles = cv2.HoughCircles(gray_blur, cv2.HOUGH_GRADIENT, dp=1.5, minDist=30,\n",
    "                                param1=50, param2=30, minRadius=20, maxRadius=150)\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "        x, y, r = circles[0][0]\n",
    "        pad = int(r * 1.5)\n",
    "        x1, y1 = max(0, x - pad), max(0, y - pad)\n",
    "        x2, y2 = min(image.shape[1], x + pad), min(image.shape[0], y + pad)\n",
    "        cropped = image[y1:y2, x1:x2]\n",
    "    else:\n",
    "        print(f\"âš ï¸ Pupil not detected in {image_path}, using full image.\")\n",
    "        cropped = image\n",
    "\n",
    "    resized = cv2.resize(cropped, output_size)\n",
    "    return resized\n",
    "\n",
    "# === 3. Save Cropped Images ===\n",
    "def preprocess_folder(input_folder, output_folder, size=(512, 512)):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for fname in tqdm(os.listdir(input_folder)):\n",
    "        if fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            path = os.path.join(input_folder, fname)\n",
    "            cropped = crop_to_pupil(path, output_size=size)\n",
    "            save_path = os.path.join(output_folder, fname)\n",
    "            cv2.imwrite(save_path, cropped)\n",
    "\n",
    "# === 4. Augmentation (for training only) ===\n",
    "augmentation_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(3)], p=0.2)\n",
    "])\n",
    "\n",
    "def augment_image(img_pil, n_augmentations=2):\n",
    "    augmented = [augmentation_transforms(img_pil) for _ in range(n_augmentations)]\n",
    "    grayscale = transforms.Grayscale()(img_pil)\n",
    "    augmented.append(grayscale.convert(\"RGB\"))\n",
    "\n",
    "    np_img = np.array(img_pil)\n",
    "    gray = cv2.cvtColor(np_img, cv2.COLOR_RGB2GRAY)\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    edge_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\n",
    "    edge_pil = Image.fromarray(edge_rgb)\n",
    "    augmented.append(edge_pil)\n",
    "    return augmented\n",
    "\n",
    "# === 5. Build DataFrame for Training ===\n",
    "def build_dataframe(folder, label, preprocess, model, device='cuda', augment=True, n_aug=3):\n",
    "    df = pd.DataFrame(columns=range(512))\n",
    "    idx = 0\n",
    "    for image_path in tqdm(glob(f\"{folder}/*.png\")):\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        images = [image]\n",
    "        if augment:\n",
    "            np_img = np.array(image)\n",
    "            for _ in range(n_aug):\n",
    "                aug_img = albumentations_aug(image=np_img)['image']\n",
    "                aug_img_pil = Image.fromarray(aug_img)\n",
    "                images.append(aug_img_pil)\n",
    "            images += augment_image(image, n_augmentations=0)\n",
    "\n",
    "        for img in images:\n",
    "            with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "                tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "                feat = model.encode_image(tensor)\n",
    "                feat = feat / feat.norm(dim=-1, keepdim=True)\n",
    "                df.loc[idx, list(range(512))] = feat.cpu().numpy()[0]\n",
    "                df.loc[idx, 'category'] = label\n",
    "                idx += 1\n",
    "    return df\n",
    "\n",
    "# === 6. Train Classifier ===\n",
    "def train_classifier(X, y):\n",
    "    model = LGBMClassifier(random_state=42)\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "# === 7. Evaluate Model ===\n",
    "def evaluate_model(model, X_val, y_val):\n",
    "    y_pred = model.predict(X_val)\n",
    "    print(confusion_matrix(y_val, y_pred))\n",
    "    print(classification_report(y_val, y_pred))\n",
    "\n",
    "# === 8. Inference with Flags ===\n",
    "def infer_on_folder(folder_path, clf, preprocess, model, device='cuda',\n",
    "                    crop=True, strict_preprocess=True, batch_size=16):\n",
    "    results = []\n",
    "    image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path)\n",
    "                   if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    for i in tqdm(range(0, len(image_paths), batch_size), desc=\"ðŸ” Batched Inference\"):\n",
    "        batch_paths = image_paths[i:i + batch_size]\n",
    "        images = []\n",
    "\n",
    "        for path in batch_paths:\n",
    "            if crop:\n",
    "                img_cv = crop_to_pupil(path)\n",
    "                img = Image.fromarray(cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB))\n",
    "            else:\n",
    "                img = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "            if strict_preprocess:\n",
    "                img = preprocess(img)\n",
    "            else:\n",
    "                img = transforms.Resize((512, 512))(img)\n",
    "                img = transforms.ToTensor()(img)\n",
    "\n",
    "            images.append(img)\n",
    "\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            batch = torch.stack(images).to(device)\n",
    "            embeddings = model.encode_image(batch)\n",
    "            embeddings = embeddings / embeddings.norm(dim=-1, keepdim=True)\n",
    "            embeddings = embeddings.cpu().numpy()\n",
    "\n",
    "        preds = clf.predict(embeddings)\n",
    "        probs = clf.predict_proba(embeddings)\n",
    "\n",
    "        for j, path in enumerate(batch_paths):\n",
    "            results.append({\n",
    "                'image_path': path,\n",
    "                'prediction': 'cataract' if preds[j] == 1 else 'normal',\n",
    "                'prob_cataract': round(probs[j][1], 4),\n",
    "                'prob_normal': round(probs[j][0], 4),\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a73ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "\n",
    "# === Helper to log sample images ===\n",
    "def log_sample_images(original_image_path, save_dir=\"sample_logs\", n_aug=3):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    image = Image.open(original_image_path).convert(\"RGB\")\n",
    "\n",
    "    original_path = f\"{save_dir}/original.png\"\n",
    "    image.save(original_path)\n",
    "    mlflow.log_artifact(original_path, artifact_path=\"images\")\n",
    "\n",
    "    aug_images = augment_image(image, n_augmentations=n_aug)\n",
    "    for i, img in enumerate(aug_images):\n",
    "        path = f\"{save_dir}/aug_{i}.png\"\n",
    "        img.save(path)\n",
    "        mlflow.log_artifact(path, artifact_path=\"images\")\n",
    "\n",
    "# === Helper to log ROC curve ===\n",
    "def log_roc_curve(y_true, y_probs, file_path=\"roc_curve.png\"):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(file_path)\n",
    "    mlflow.log_artifact(file_path)\n",
    "    mlflow.log_metric(\"val_roc_auc\", roc_auc)\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=\"CLIP_LGBM_Cataract_Classifier\"):\n",
    "    mlflow.set_tag(\"clip_model\", \"ViT-B-32\")\n",
    "    mlflow.log_param(\"device\", 'cpu')\n",
    "    mlflow.log_param(\"n_augmentations\", 3)\n",
    "    mlflow.log_param(\"dataset_path\", \"processed_aug_aug/train/\")\n",
    "\n",
    "    # Load model\n",
    "    model, preprocess, tokenizer, device = load_clip()\n",
    "\n",
    "    # Step A: Preprocess\n",
    "    preprocess_folder(\"processed_images/train/normal\", \"processed_aug_aug/train/normal\")\n",
    "    preprocess_folder(\"processed_images/train/cataract\", \"processed_aug_aug/train/cataract\")\n",
    "\n",
    "    # Log sample images\n",
    "    normal_samples = random.sample(glob(\"processed_aug_aug/train/normal/*.png\"), 1)\n",
    "    cataract_samples = random.sample(glob(\"processed_aug_aug/train/cataract/*.png\"), 1)\n",
    "    for sample in normal_samples + cataract_samples:\n",
    "        log_sample_images(sample)\n",
    "\n",
    "    # Step B: Build dataset\n",
    "    start_train_time = time.time()\n",
    "    df_normal = build_dataframe(\"processed_aug_aug/train/normal\", 0, preprocess, model, device=device)\n",
    "    df_cataract = build_dataframe(\"processed_aug_aug/train/cataract\", 1, preprocess, model, device=device)\n",
    "    df = pd.concat([df_normal, df_cataract]).astype(float).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    X = df.iloc[:, :512]\n",
    "    y = df['category']\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "    # Step C: Train model\n",
    "    clf = train_classifier(X_train, y_train)\n",
    "    mlflow.sklearn.log_model(clf, \"lgbm_model_initial\")\n",
    "\n",
    "    # Evaluate model\n",
    "    y_pred = clf.predict(X_val)\n",
    "    y_probs = clf.predict_proba(X_val)[:, 1]\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    mlflow.log_metric(\"val_accuracy\", acc)\n",
    "    mlflow.log_metric(\"val_f1_score\", f1)\n",
    "\n",
    "    report = classification_report(y_val, y_pred, output_dict=True)\n",
    "    mlflow.log_metric(\"val_precision_cataract\", report[\"1.0\"][\"precision\"])\n",
    "    mlflow.log_metric(\"val_recall_cataract\", report[\"1.0\"][\"recall\"])\n",
    "\n",
    "    log_roc_curve(y_val, y_probs)\n",
    "\n",
    "    end_train_time = time.time()\n",
    "    mlflow.log_metric(\"train_time_sec\", end_train_time - start_train_time)\n",
    "\n",
    "    # Step D: Grid Search\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 5, 7],\n",
    "    }\n",
    "    grid = GridSearchCV(LGBMClassifier(verbose=-1), param_grid, cv=3)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "    mlflow.sklearn.log_model(best_model, \"lgbm_model_best\")\n",
    "    mlflow.log_params(grid.best_params_)\n",
    "\n",
    "    # Step E: Inference (strict)\n",
    "    start_infer_strict = time.time()\n",
    "    df_results_cat_strict = infer_on_folder(\n",
    "        \"processed_images/test/cataract/\", best_model, preprocess, model,\n",
    "        device=device, crop=True, strict_preprocess=True, batch_size=32\n",
    "    )\n",
    "    end_infer_strict = time.time()\n",
    "    mlflow.log_metric(\"inference_time_strict\", end_infer_strict - start_infer_strict)\n",
    "    mlflow.log_metric(\"cataract_detected_strict\", (df_results_cat_strict['prob_cataract'] > 0.5).sum())\n",
    "\n",
    "    df_results_cat_strict.to_csv(\"strict_preds.csv\", index=False)\n",
    "    mlflow.log_artifact(\"strict_preds.csv\")\n",
    "\n",
    "    print(\"\\nðŸŽ¯ MLflow run complete. All results logged.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
